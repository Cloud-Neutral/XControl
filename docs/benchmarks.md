# 模型性能基准

以下结果来自在 `http://127.0.0.1:11434/v1/chat/completions` 接口上，使用提示语「你好，简要介绍一下自己」进行的基准测试。

## 场景：交互延迟（短答）（max_tokens=64）

| Model | HTTP | TTFT | Total | InTok | OutTok | Req/s | Avg(s) | P90(s) | P95(s) | OutTok/s | GenTok/s |
|-------|------|------|-------|-------|--------|-------|--------|--------|--------|----------|-----------|
| llama2:7b       | 200 | 1.233 | 1.233 | 37 | 64  | 0.8153 | 2.3914 | 2.4653 | 2.4657 | 51.91 | 1333333.33 |
| llama2:13b      | 200 | 2.236 | 2.237 | 37 | 64  | 0.4480 | 4.3526 | 4.4877 | 4.4901 | 28.62 | 1729729.73 |
| llama3:latest   | 200 | 1.403 | 1.403 | 18 | 64  | 0.7210 | 2.7047 | 2.7741 | 2.8062 | 45.63 | 1333333.33 |

说明：InTok = 输入 tokens，OutTok = 输出 tokens；OutTok/s = OutTok/Total；GenTok/s = OutTok/(Total-TTFT)。

## 场景：生成吞吐（长答）（max_tokens=200）

| Model | HTTP | TTFT | Total | InTok | OutTok | Req/s | Avg(s) | P90(s) | P95(s) | OutTok/s | GenTok/s |
|-------|------|------|-------|-------|--------|-------|--------|--------|--------|----------|-----------|
| llama2:7b       | 200 | 1.881 | 1.881 | 37 | 97  | 0.4301 | 4.5587 | 6.1121 | 6.2199 | 51.58 | 2108695.65 |
| llama2:13b      | 200 | 2.873 | 2.873 | 37 | 83  | 0.2927 | 6.6773 | 7.6938 | 8.2401 | 28.89 | 1693877.55 |
| llama3:latest   | 200 | 4.001 | 4.001 | 18 | 184 | 0.2639 | 7.3946 | 8.4650 | 8.5507 | 45.99 | 4600000.00 |

说明：InTok = 输入 tokens，OutTok = 输出 tokens；OutTok/s = OutTok/Total；GenTok/s = OutTok/(Total-TTFT)。

